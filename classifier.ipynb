{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunav/.local/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import gentle\n",
    "import math\n",
    "import numpy as np\n",
    "import librosa\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import scipy.io.wavfile as sciwav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISFLUENCIES = {'uh', 'um'}  # set of disfluencies\n",
    "RESOURCES = gentle.Resources()\n",
    "N_THREADS = mp.cpu_count()\n",
    "logging.getLogger().setLevel(\"INFO\")\n",
    "EPS = 1e-8  # 0.00000001\n",
    "OPTIMAL_DURATION = 0.115\n",
    "win_length = 0.025\n",
    "win_step = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_model(model, out_path):\n",
    "    chk_file = glob.glob(out_path + '/' + '*.pth')\n",
    "\n",
    "    if chk_file:\n",
    "        chk_file = str(chk_file[0])\n",
    "        print('found modeL {}, restoring'.format(chk_file))\n",
    "        model.load_state_dict(torch.load(chk_file, map_location=torch.device('cpu')))\n",
    "    else:\n",
    "        print('Model not found, using untrained model')\n",
    "    return model\n",
    "\n",
    "\n",
    "def restore_objects(out_path, default):\n",
    "    data_file = glob.glob(out_path + '/' + '*.dat')\n",
    "    if data_file:\n",
    "        data_file = str(data_file[0])\n",
    "        print('found data {}, restoring'.format(data_file))\n",
    "        with open(data_file, 'rb') as input_:\n",
    "            obj = pickle.load(input_)\n",
    "\n",
    "        return obj\n",
    "    else:\n",
    "        return default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _on_progress(p):\n",
    "    for k, v in p.items():\n",
    "        logging.debug(\"%s: %s\" % (k, v))\n",
    "        \n",
    "\n",
    "def _get_key_val_pair(line):\n",
    "    line_split = line[:-1].split()\n",
    "    word = line_split[0]\n",
    "    if word[-1] == ')':\n",
    "        word = word.split('(')[0]\n",
    "\n",
    "    word = word.lower()\n",
    "    key = [word]\n",
    "    val = []\n",
    "    for phoneme in line_split[1:]:\n",
    "        val.append(phoneme.lower())\n",
    "        if phoneme[-1].isdigit():\n",
    "            phoneme = phoneme[:-1]\n",
    "\n",
    "        phoneme = phoneme.lower()\n",
    "        key.append(phoneme)\n",
    "\n",
    "    key = \" \".join(key)\n",
    "    val = tuple(val)\n",
    "    return key, val\n",
    "\n",
    "def _create_dict():\n",
    "    phoneme_alignment_dict = dict()\n",
    "\n",
    "    cmu_file = open('/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/alignment/cmudict-0.7b.txt', 'r')\n",
    "    for line in cmu_file:\n",
    "        key, val = _get_key_val_pair(line)\n",
    "        phoneme_alignment_dict[key] = val\n",
    "\n",
    "    return phoneme_alignment_dict\n",
    "\n",
    "def align_audio(wav_path, transcript):\n",
    "    with gentle.resampled(wav_path) as wavfile:\n",
    "        print(\"starting alignment {}\".format(wav_path))\n",
    "        aligner = gentle.ForcedAligner(RESOURCES, transcript, nthreads=N_THREADS, disfluency=False,\n",
    "                                       conservative=False, disfluencies=DISFLUENCIES)\n",
    "        result = aligner.transcribe(wavfile, progress_cb=_on_progress, logging=logging)\n",
    "        result_json = json.loads(result.to_json())\n",
    "\n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(signal, samplerate):\n",
    "    # in librosa the window length and step size (stride) are set by number of frames and not\n",
    "    # duration. window_length is set by n_fft and step is set by hop_length\n",
    "    frame_length = int(0.025 * samplerate)\n",
    "    step_size = int(0.01 * samplerate)\n",
    "    mfcc = librosa.feature.mfcc(signal, samplerate, n_mfcc=13, n_fft=frame_length, hop_length=step_size, center=False)\n",
    "    mfcc_derivative = librosa.feature.delta(mfcc, order=1)\n",
    "    mfcc_second_derivative = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "    assert mfcc.shape == (13, 10)\n",
    "    assert mfcc_derivative.shape == (13, 10)\n",
    "    assert mfcc_second_derivative.shape == (13, 10)\n",
    "\n",
    "    # stack mfcc, derivative and second derivative horizontally\n",
    "    mfcc_matrix = np.concatenate([mfcc, mfcc_derivative, mfcc_second_derivative], axis=1)\n",
    "    assert mfcc_matrix.shape == (13, 30)\n",
    "\n",
    "    return mfcc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2frame(signal, frame_length, frame_step, winfunc=lambda x: np.ones((x,))):\n",
    "    \"\"\"\n",
    "    Frame a signal into overlapping frames.\n",
    "    :param signal: the audio signal to frame.\n",
    "    :param frame_length: length of each frame measured in samples.\n",
    "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
    "    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n",
    "    \"\"\"\n",
    "    signal_length = len(signal)\n",
    "    frame_length = int(round(frame_length))\n",
    "    frame_step = int(round(frame_step))\n",
    "    if signal_length <= frame_length:\n",
    "        frames_num = 1\n",
    "    else:\n",
    "        frames_num = 1 + int(math.ceil((1.0 * signal_length - frame_length) / frame_step))\n",
    "\n",
    "    pad_length = int((frames_num - 1) * frame_step + frame_length)\n",
    "\n",
    "    zeros = np.zeros((pad_length - signal_length,))\n",
    "    pad_signal = np.concatenate((signal, zeros))\n",
    "\n",
    "    indices = np.tile(np.arange(0, frame_length), (frames_num, 1)) + np.tile(\n",
    "        np.arange(0, frames_num * frame_step, frame_step), (frame_length, 1)).T\n",
    "    indices = np.array(indices, dtype=np.int32)\n",
    "    frames = pad_signal[indices]\n",
    "    win = np.tile(winfunc(frame_length), (frames_num, 1))\n",
    "\n",
    "    return frames * win\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p2pamplitude(signal):\n",
    "    \"\"\"\n",
    "    f1 : Compute the peak-to-peak amplitude of the signal\n",
    "    \"\"\"\n",
    "    return np.max(signal) - np.min(signal)\n",
    "\n",
    "\n",
    "def get_mean_energy_over_syllable_nucleus(energy):\n",
    "    \"\"\"\n",
    "    f2 : Mean energy over syllable nucleus\n",
    "    \"\"\"\n",
    "    return np.mean(energy)\n",
    "\n",
    "\n",
    "def get_max_energy_over_syllable_nucleus(energy):\n",
    "    \"\"\"\n",
    "    f3 : Max energy over syllable nucleus\n",
    "    \"\"\"\n",
    "    return np.max(energy)\n",
    "\n",
    "\n",
    "def get_duration(signal, samplerate):\n",
    "    \"\"\"\n",
    "    f4 & f5 : Duration of a sound wave. Send input (syllable/vowel) accordingly\n",
    "    \"\"\"\n",
    "    len_frames = len(signal)\n",
    "    return len_frames / samplerate\n",
    "\n",
    "\n",
    "def get_max_pitch_over_syllable_nucleus(pitch_for_frames):\n",
    "    \"\"\"\n",
    "    f6 : Maximum pitch over syllable nucleus\n",
    "    \"\"\"\n",
    "    return np.max(pitch_for_frames)\n",
    "\n",
    "\n",
    "def get_mean_pitch_over_syllable_nucleus(pitch_for_frames):\n",
    "    \"\"\"\n",
    "    f7 : Mean pitch over syllable nucleus\n",
    "    \"\"\"\n",
    "    return np.mean(pitch_for_frames)\n",
    "\n",
    "def pitch_from_zcr(frame, fs):\n",
    "    \"\"\"\n",
    "    The function detects the F0 of isolated phoneme by zero-crossing\n",
    "    \"\"\"\n",
    "    M = np.round(0.016 * fs) - 1\n",
    "    # print (frames.shape)\n",
    "    R = np.correlate(frame, frame, mode='full')\n",
    "    g = R[len(frame) - 1]\n",
    "    R = R[len(frame):-1]\n",
    "    # estimate m0 (as the first zero crossing of R)\n",
    "    [a, ] = np.nonzero(np.diff(np.sign(R)))\n",
    "    if len(a) == 0:\n",
    "        m0 = len(R) - 1\n",
    "    else:\n",
    "        m0 = a[0]\n",
    "\n",
    "    if M > len(R):\n",
    "        M = len(R) - 1\n",
    "\n",
    "    M = int(M)\n",
    "    m0 = int(m0)\n",
    "    Gamma = np.zeros(M)\n",
    "    CSum = np.cumsum(frame ** 2)\n",
    "    Gamma[m0:M] = R[m0:M] / (np.sqrt((g * CSum[M:m0:-1])) + EPS)\n",
    "    ZCR = zcr(Gamma)\n",
    "    if ZCR[1] > 0.15:\n",
    "        HR = 0.0\n",
    "        f0 = 0.0\n",
    "    else:\n",
    "        if len(Gamma) == 0:\n",
    "            HR = 1.0\n",
    "            blag = 0.0\n",
    "            Gamma = np.zeros((M), dtype=np.float64)\n",
    "        else:\n",
    "            HR = np.max(Gamma)\n",
    "            blag = np.argmax(Gamma)\n",
    "        # Get fundamental frequency:\n",
    "        f0 = fs / (blag + EPS)\n",
    "        if f0 > 5000:\n",
    "            f0 = 0.0\n",
    "        if HR < 0.1:\n",
    "            f0 = 0.0\n",
    "    pitch = f0\n",
    "    return HR, pitch\n",
    "\n",
    "\n",
    "def zcr(frame):\n",
    "    \"\"\"\n",
    "    Compute the number and rate of sign-changes of the signal during the duration of a particular frame\n",
    "    \"\"\"\n",
    "    count = len(frame)\n",
    "    countZC = np.sum(np.abs(np.diff(np.sign(frame)))) / 2\n",
    "    return countZC, (np.float64(countZC) / np.float64(count - 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy_for_frame(frame):\n",
    "    \"\"\"\n",
    "    Compute energy value of frame\n",
    "    \"\"\"\n",
    "    return np.sum(frame ** 2) / np.float64(len(frame))\n",
    "\n",
    "\n",
    "def get_energy_for_frames(frames):\n",
    "    \"\"\"\n",
    "    Compute energy value for all frames\n",
    "    \"\"\"\n",
    "    energy = []\n",
    "    for i in range(len(frames)):\n",
    "        energy.append(get_energy_for_frame(frames[i]))\n",
    "    return energy\n",
    "\n",
    "\n",
    "def get_pitch_values(frames, fs):\n",
    "    \"\"\"\n",
    "    Compute pitch values for all frames\n",
    "    \"\"\"\n",
    "    pitch_for_frames = []\n",
    "    for i in range(len(frames)):\n",
    "        pitch_for_frames.append(pitch_from_zcr(frames[i], fs))\n",
    "    return pitch_for_frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_mfcc(signal, samplerate):\n",
    "    \"\"\"\n",
    "    Compute the non-MFCC features of the signal, these include:\n",
    "    f1 : Compute the peak-to-peak amplitude of the signal\n",
    "    f2 : Mean energy over syllable nucleus\n",
    "    f3 : Max energy over syllable nucleus\n",
    "    f4 : Duration of a vowel nucleus\n",
    "    f5 : Maximum pitch over syllable nucleus\n",
    "    f6 : Mean pitch over syllable nucleus\n",
    "    \"\"\"\n",
    "\n",
    "    non_mfcc_features = np.zeros(6)\n",
    "    frames = audio2frame(signal, win_length * samplerate, win_step * samplerate)\n",
    "    energy = get_energy_for_frames(frames)\n",
    "    pitch_vals = get_pitch_values(frames, samplerate)\n",
    "    non_mfcc_features[0] = get_p2pamplitude(signal)\n",
    "    non_mfcc_features[1] = get_mean_energy_over_syllable_nucleus(energy)\n",
    "    non_mfcc_features[2] = get_max_energy_over_syllable_nucleus(energy)\n",
    "    non_mfcc_features[3] = get_duration(signal, samplerate)\n",
    "    non_mfcc_features[4] = get_max_pitch_over_syllable_nucleus(pitch_vals)\n",
    "    non_mfcc_features[5] = get_mean_pitch_over_syllable_nucleus(pitch_vals)\n",
    "    return non_mfcc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRU(OrderedDict):\n",
    "    \"\"\"Limit size, evicting the least recently looked-up key when full\"\"\"\n",
    "    def __init__(self, maxsize=128, *args, **kwargs):\n",
    "        self.maxsize = maxsize\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        value = super().__getitem__(key)\n",
    "        self.move_to_end(key)\n",
    "        return value\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super().__setitem__(key, value)\n",
    "        if len(self) > self.maxsize:\n",
    "            oldest = next(iter(self))\n",
    "            del self[oldest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phoneme:\n",
    "    def __init__(self, path, id_, word, phoneme):\n",
    "        self.path = path\n",
    "        self.id_ = id_\n",
    "        self.word = word\n",
    "        self.phoneme = phoneme\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleExtraction:\n",
    "    def __init__(self, wav_root, alignment_file, out_dir,label):\n",
    "        self.wav_root = wav_root\n",
    "        self.alignment_file = alignment_file\n",
    "        self.out_dir = out_dir\n",
    "        self.label = label\n",
    "        self.pool = mp.Pool(mp.cpu_count())\n",
    "        self.make_directories()\n",
    "\n",
    "    def make_directories(self):\n",
    "        os.makedirs(self.out_dir + '/0', exist_ok=True)\n",
    "        os.makedirs(self.out_dir + '/1', exist_ok=True)\n",
    "        print('Created directories for each label in path: {}'.format(self.out_dir))\n",
    "\n",
    "    def get_phoneme_features(self, index, n, vowel_phonemes, features_cache):\n",
    "        # if out of bound then\n",
    "        if index < 0 or index >= n:\n",
    "            return np.zeros(shape=(1, 13, 30), dtype=np.float32), np.zeros(6, dtype=np.float32)\n",
    "\n",
    "        phoneme = vowel_phonemes[index]\n",
    "\n",
    "        if phoneme not in features_cache:\n",
    "            signal, samplerate = librosa.load(self.wav_root + '/' + phoneme.path, sr=None)\n",
    "            optimal_signal_len = int(samplerate * OPTIMAL_DURATION)\n",
    "\n",
    "            signal_len = len(signal)\n",
    "            excess = signal_len - optimal_signal_len\n",
    "            left_pad = abs(excess // 2)\n",
    "            right_pad = abs(excess) - left_pad\n",
    "\n",
    "            if signal_len > optimal_signal_len:\n",
    "                signal_mfcc = signal[left_pad:-right_pad]\n",
    "\n",
    "            elif signal_len < optimal_signal_len:\n",
    "                signal_mfcc = np.concatenate([np.zeros(left_pad), signal, np.zeros(right_pad)], axis=0)\n",
    "            else:\n",
    "                signal_mfcc = signal\n",
    "\n",
    "            # extract MFCC features, should be a matrix of shape (1, 13, 30)\n",
    "            mfcc_features = get_mfcc(signal_mfcc, samplerate)\n",
    "            # returned np array is of shape (13, 30), add a new channel axis\n",
    "            mfcc_features = mfcc_features[np.newaxis, :, :]\n",
    "\n",
    "            # extract non MFCC features, should be a vector of shape (6,)\n",
    "            non_mfcc_features = get_non_mfcc(signal, samplerate)\n",
    "\n",
    "            features_cache[phoneme] = (mfcc_features, non_mfcc_features)\n",
    "\n",
    "        return features_cache[phoneme]\n",
    "\n",
    "    def generate_samples(self, vowel_phonemes):\n",
    "        n = len(vowel_phonemes)\n",
    "        features_cache = LRU(size=5)\n",
    "        for i in range(n):\n",
    "            phoneme = vowel_phonemes[i]\n",
    "            #label = phoneme.phoneme[-1]\n",
    "\n",
    "            pre_mfcc, pre_non_mfcc = self.get_phoneme_features(i - 1, n, vowel_phonemes, features_cache)\n",
    "            anchor_mfcc, anchor_non_mfcc = self.get_phoneme_features(i, n, vowel_phonemes, features_cache)\n",
    "            suc_mfcc, suc_non_mfcc = self.get_phoneme_features(i + 1, n, vowel_phonemes, features_cache)\n",
    "\n",
    "            mfcc_tensor = np.concatenate([pre_mfcc, anchor_mfcc, suc_mfcc], axis=0)\n",
    "            non_mfcc_vector = np.concatenate([pre_non_mfcc, anchor_non_mfcc, suc_non_mfcc], axis=0)\n",
    "            file_name = phoneme.id_ + '_' + phoneme.word + '_' + phoneme.phoneme\n",
    "            np.save(self.out_dir + '/' + self.label + '/' + file_name + '_mfcc.npy', mfcc_tensor)\n",
    "            np.save(self.out_dir + '/' + self.label + '/' + file_name + '_other.npy', non_mfcc_vector)\n",
    "\n",
    "        print('finished writing {} samples for id: {}, word: {}'.\n",
    "              format(n, vowel_phonemes[0].id_, vowel_phonemes[0].word))\n",
    "\n",
    "    def extract_features(self):\n",
    "        phoneme_alignment_file = open(self.alignment_file, 'r')\n",
    "        current_word = None\n",
    "        curr_vowels = []\n",
    "        for line in phoneme_alignment_file:\n",
    "            path, word, phoneme = line[:-1].split('\\t')\n",
    "            id_='1'\n",
    "            phoneme = Phoneme(path, id_, word, phoneme)\n",
    "            if not current_word:\n",
    "                current_word = (id_, word)\n",
    "                if phoneme.phoneme[-1].isnumeric():\n",
    "                    curr_vowels.append(phoneme)\n",
    "\n",
    "            elif current_word == (id_, word):\n",
    "                if phoneme.phoneme[-1].isnumeric():\n",
    "                    curr_vowels.append(phoneme)\n",
    "\n",
    "            elif current_word != (id_, word):\n",
    "                # new word encountered. create training samples from the old list\n",
    "                self.pool.apply_async(self.generate_samples, args=[curr_vowels])\n",
    "\n",
    "                # overwrite the curr_word and curr_vowels\n",
    "                current_word = (id_, word)\n",
    "                curr_vowels = []\n",
    "                if phoneme.phoneme[-1].isnumeric():\n",
    "                    curr_vowels.append(phoneme)\n",
    "\n",
    "        self.pool.apply(self.generate_samples, args=[curr_vowels])\n",
    "        phoneme_alignment_file.close()\n",
    "        self.pool.close()\n",
    "        self.pool.join()\n",
    "\n",
    "    def __getstate__(self):\n",
    "        self_dict = self.__dict__.copy()\n",
    "        del self_dict['pool']\n",
    "        return self_dict\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_root='/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/dev-clean/2412/153948'\n",
    "wav_file='2412-153948-0004.wav'\n",
    "phoneme_path='/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/temp'\n",
    "output_csv='/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/temp_csv.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHEEP AND CATTLE WERE INTRODUCED AND BRED WITH EXTREME RAPIDITY MEN TOOK UP THEIR FIFTY THOUSAND OR ONE HUNDRED THOUSAND ACRES OF COUNTRY GOING INLAND ONE BEHIND THE OTHER TILL IN A FEW YEARS THERE WAS NOT AN ACRE BETWEEN THE SEA AND THE FRONT RANGES WHICH WAS NOT TAKEN UP AND STATIONS EITHER FOR SHEEP OR CATTLE WERE SPOTTED ABOUT AT INTERVALS OF SOME TWENTY OR THIRTY MILES OVER THE WHOLE COUNTRY\n",
      "starting alignment /home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/dev-clean/2412/153948/2412-153948-0004.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:1/2\n",
      "INFO:root:2/2\n",
      "INFO:root:2 unaligned words (of 73)\n",
      "INFO:root:after 2nd pass: 2 unaligned words (of 73)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: {'alignedWord': 'extreme', 'case': 'success', 'end': 2.81, 'endOffset': 54, 'phones': [{'duration': 0.06, 'phone': 'eh_B'}, {'duration': 0.09, 'phone': 'k_I'}, {'duration': 0.02, 'phone': 's_I'}, {'duration': 0.06, 'phone': 't_I'}, {'duration': 0.04, 'phone': 'r_I'}, {'duration': 0.09, 'phone': 'iy_I'}, {'duration': 0.06, 'phone': 'm_E'}], 'start': 2.39, 'startOffset': 47, 'word': 'EXTREME'} not in dict, skipping...\n",
      "word: {'alignedWord': '<unk>', 'case': 'success', 'end': 3.41, 'endOffset': 63, 'phones': [{'duration': 0.6, 'phone': 'oov_S'}], 'start': 2.81, 'startOffset': 55, 'word': 'RAPIDITY'} not in dict, skipping...\n",
      "word: {'alignedWord': 'was', 'case': 'success', 'end': 11.44, 'endOffset': 201, 'phones': [{'duration': 0.05, 'phone': 'w_B'}, {'duration': 0.05, 'phone': 'ah_I'}, {'duration': 0.07, 'phone': 'z_E'}], 'start': 11.27, 'startOffset': 198, 'word': 'WAS'} not in dict, skipping...\n",
      "word: {'alignedWord': 'was', 'case': 'success', 'end': 14.329998999999999, 'endOffset': 260, 'phones': [{'duration': 0.05, 'phone': 'w_B'}, {'duration': 0.06, 'phone': 'ah_I'}, {'duration': 0.08, 'phone': 'z_E'}], 'start': 14.139999, 'startOffset': 257, 'word': 'WAS'} not in dict, skipping...\n",
      "word: {'alignedWord': 'thirty', 'case': 'success', 'end': 20.69, 'endOffset': 370, 'phones': [{'duration': 0.11, 'phone': 'th_B'}, {'duration': 0.08, 'phone': 'er_I'}, {'duration': 0.06, 'phone': 't_I'}, {'duration': 0.05, 'phone': 'iy_E'}], 'start': 20.39, 'startOffset': 364, 'word': 'THIRTY'} not in dict, skipping...\n",
      "done alignment and slicing for file: /home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/dev-clean/2412/153948/2412-153948-0004.wav\n"
     ]
    }
   ],
   "source": [
    "out_file = open(output_csv, 'w')\n",
    "alignment_dict = _create_dict()\n",
    "wav_file = wav_root + '/' + wav_file\n",
    "sr, signal = sciwav.read(wav_file)\n",
    "transcript =\"SHEEP AND CATTLE WERE INTRODUCED AND BRED WITH EXTREME RAPIDITY MEN TOOK UP THEIR FIFTY THOUSAND OR ONE HUNDRED THOUSAND ACRES OF COUNTRY GOING INLAND ONE BEHIND THE OTHER TILL IN A FEW YEARS THERE WAS NOT AN ACRE BETWEEN THE SEA AND THE FRONT RANGES WHICH WAS NOT TAKEN UP AND STATIONS EITHER FOR SHEEP OR CATTLE WERE SPOTTED ABOUT AT INTERVALS OF SOME TWENTY OR THIRTY MILES OVER THE WHOLE COUNTRY\"\n",
    "print(transcript)\n",
    "alignment = align_audio(wav_file, transcript)\n",
    "\n",
    "for word in alignment['words']:\n",
    "    if word['case'] != 'success':\n",
    "        continue\n",
    "\n",
    "    start_time, end_time = word['start'], word['end']\n",
    "    aligned_word = word['alignedWord']\n",
    "    key = [aligned_word.lower()]\n",
    "    for phoneme in word['phones']:\n",
    "        phone = phoneme['phone']\n",
    "        key.append(phone.split('_')[0])\n",
    "\n",
    "    key = ' '.join(key)\n",
    "    phoneme_tuple = alignment_dict.get(key, ())\n",
    "\n",
    "    if len(phoneme_tuple) == 0:\n",
    "        print('word: {} not in dict, skipping...'.format(word))\n",
    "        continue\n",
    "\n",
    "    if len(phoneme_tuple) != len(word['phones']):\n",
    "        print('word: {} not aligned properly, skipping...'.format(word))\n",
    "        continue\n",
    "\n",
    "    # now map phonemes and slice wav\n",
    "    for i, phoneme in enumerate(word['phones']):\n",
    "        phone_start = start_time\n",
    "        phone_end = phone_start + phoneme['duration']\n",
    "        # check if vowel phoneme\n",
    "        if phoneme_tuple[i][-1].isdigit():\n",
    "\n",
    "            file_name =  aligned_word + '_' + phoneme_tuple[i] + '_' + \\\n",
    "                        str(int(phone_start * 1000)) + '_' + str(int(phone_end * 1000)) + '.wav'\n",
    "\n",
    "            start_frame, end_frame = int(phone_start * sr), int(phone_end * sr)\n",
    "            sciwav.write(phoneme_path + '/' + file_name, sr, signal[start_frame:end_frame])\n",
    "            out_file.write(file_name + '\\t' +  aligned_word + '\\t' + phoneme_tuple[i] + '\\n')\n",
    "        start_time = phone_end\n",
    "\n",
    "print('done alignment and slicing for file: {}'.format(wav_file))\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing 1 samples for id: 1, word: were\n",
      "finished writing 1 samples for id: 1, word: sheep\n",
      "finished writing 1 samples for id: 1, word: and\n",
      "finished writing 2 samples for id: 1, word: cattle\n",
      "Created directories for each label in path: /home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/temp_feat\n",
      "finished writing 1 samples for id: 1, word: bred\n",
      "finished writing 1 samples for id: 1, word: and\n",
      "finished writing 1 samples for id: 1, word: with\n",
      "finished writing 1 samples for id: 1, word: men\n",
      "finished writing 1 samples for id: 1, word: took\n",
      "finished writing 1 samples for id: 1, word: up\n",
      "finished writing 1 samples for id: 1, word: their\n",
      "finished writing 3 samples for id: 1, word: introduced\n",
      "finished writing 2 samples for id: 1, word: fifty\n",
      "finished writing 1 samples for id: 1, word: or\n",
      "finished writing 1 samples for id: 1, word: one\n",
      "finished writing 2 samples for id: 1, word: thousand\n",
      "finished writing 2 samples for id: 1, word: hundred\n",
      "finished writing 1 samples for id: 1, word: of\n",
      "finished writing 2 samples for id: 1, word: thousand\n",
      "finished writing 2 samples for id: 1, word: country\n",
      "finished writing 2 samples for id: 1, word: acres\n",
      "finished writing 1 samples for id: 1, word: one\n",
      "finished writing 2 samples for id: 1, word: going\n",
      "finished writing 2 samples for id: 1, word: inland\n",
      "finished writing 1 samples for id: 1, word: the\n",
      "finished writing 2 samples for id: 1, word: behind\n",
      "finished writing 1 samples for id: 1, word: till\n",
      "finished writing 2 samples for id: 1, word: other\n",
      "finished writing 1 samples for id: 1, word: a\n",
      "finished writing 1 samples for id: 1, word: in\n",
      "finished writing 1 samples for id: 1, word: few\n",
      "finished writing 1 samples for id: 1, word: there\n",
      "finished writing 1 samples for id: 1, word: an\n",
      "finished writing 1 samples for id: 1, word: not\n",
      "finished writing 1 samples for id: 1, word: years\n",
      "finished writing 1 samples for id: 1, word: the\n",
      "finished writing 2 samples for id: 1, word: acre\n",
      "finished writing 1 samples for id: 1, word: sea\n",
      "finished writing 1 samples for id: 1, word: and\n",
      "finished writing 1 samples for id: 1, word: the\n",
      "finished writing 1 samples for id: 1, word: front\n",
      "finished writing 2 samples for id: 1, word: between\n",
      "finished writing 1 samples for id: 1, word: not\n",
      "finished writing 1 samples for id: 1, word: which\n",
      "finished writing 2 samples for id: 1, word: ranges\n",
      "finished writing 1 samples for id: 1, word: up\n",
      "finished writing 1 samples for id: 1, word: and\n",
      "finished writing 2 samples for id: 1, word: taken\n",
      "finished writing 1 samples for id: 1, word: for\n",
      "finished writing 2 samples for id: 1, word: either\n",
      "finished writing 2 samples for id: 1, word: stations\n",
      "finished writing 1 samples for id: 1, word: sheep\n",
      "finished writing 1 samples for id: 1, word: or\n",
      "finished writing 1 samples for id: 1, word: were\n",
      "finished writing 2 samples for id: 1, word: cattle\n",
      "finished writing 2 samples for id: 1, word: about\n",
      "finished writing 2 samples for id: 1, word: spotted\n",
      "finished writing 1 samples for id: 1, word: at\n",
      "finished writing 1 samples for id: 1, word: of\n",
      "finished writing 1 samples for id: 1, word: or\n",
      "finished writing 1 samples for id: 1, word: miles\n",
      "finished writing 3 samples for id: 1, word: intervals\n",
      "finished writing 1 samples for id: 1, word: whole\n",
      "finished writing 1 samples for id: 1, word: the\n",
      "finished writing 2 samples for id: 1, word: over\n",
      "finished writing 2 samples for id: 1, word: country\n"
     ]
    }
   ],
   "source": [
    "out_dir='/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/temp_feat'\n",
    "sample_extraction = SampleExtraction(phoneme_path, output_csv, out_dir,'0')\n",
    "sample_extraction.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import DatasetFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.dataset_folder = DatasetFolder(root=root, loader=CNNDataset._npy_loader, extensions=('_mfcc.npy',))\n",
    "        self.len_ = len(self.dataset_folder)\n",
    "        self.folder_to_index = self.dataset_folder.class_to_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def _npy_loader(path):\n",
    "        mfcc = np.load(path)\n",
    "        non_mfcc_file_path = path.replace('mfcc', 'other')\n",
    "        non_mfcc = np.load(non_mfcc_file_path)\n",
    "\n",
    "        # in_channels x height x width\n",
    "        assert mfcc.shape == (3, 13, 30)\n",
    "        assert non_mfcc.shape == (18, )\n",
    "\n",
    "        mfcc = torch.from_numpy(mfcc).float()\n",
    "        non_mfcc = torch.from_numpy(non_mfcc).float()\n",
    "\n",
    "        return mfcc, non_mfcc, path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.dataset_folder[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                      padding=padding, stride=stride),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "                      padding=padding, stride=stride),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.network(x)\n",
    "        out = out + x\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNStressNet(nn.Module):\n",
    "\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.loss_layer = nn.CrossEntropyLoss(reduction=reduction)\n",
    "        self.cnn_network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=(3 - 1)//2, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=(3 - 1)//2, stride=2),\n",
    "            ResBlock(in_channels=32, out_channels=32, kernel_size=3),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=(3 - 1) // 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=(0, (3 - 1) // 2), stride=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4))\n",
    "        )\n",
    "\n",
    "        self.dnn_network = nn.Sequential(\n",
    "            nn.Linear(18, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, mfcc, non_mfcc):\n",
    "        n = mfcc.shape[0]\n",
    "        cnn_out = self.cnn_network(mfcc)\n",
    "        cnn_out = cnn_out.reshape(n, 64)\n",
    "\n",
    "        dnn_out = self.dnn_network(non_mfcc)\n",
    "\n",
    "        out = torch.cat([cnn_out, dnn_out], dim=1)\n",
    "        out = self.fully_connected(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, predictions, labels):\n",
    "        loss_val = self.loss_layer(predictions, labels)\n",
    "        return loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path='/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/temp_feat'\n",
    "model_path='/home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/colab_data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found modeL /home/arunav/Desktop/8th-semester/RE/lexical-stress-detection-master/data/colab_data/models/9.pth, restoring\n"
     ]
    }
   ],
   "source": [
    "kwargs =  {}\n",
    "\n",
    "test_dataset = CNNDataset(root=test_path)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "model = CNNStressNet(reduction='mean')\n",
    "model = restore_model(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "output=[]\n",
    "for batch_idx, ((mfcc, non_mfcc, path), label) in enumerate(tqdm.tqdm(test_loader)):\n",
    "    out = model(mfcc, non_mfcc)\n",
    "    prob = torch.nn.functional.softmax(out, dim=1)\n",
    "    output.append(prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=output[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9999880790710449, 1.1899972378159873e-05],\n",
       " [4.652678398997523e-06, 0.9999953508377075],\n",
       " [0.9999973773956299, 2.676935309864348e-06],\n",
       " [0.9999867677688599, 1.326670462731272e-05],\n",
       " [0.999984622001648, 1.5382012861664407e-05],\n",
       " [0.9989761114120483, 0.0010238814866170287],\n",
       " [0.9994372725486755, 0.0005626857164315879],\n",
       " [0.9999798536300659, 2.0105633666389622e-05],\n",
       " [5.239860989547651e-09, 1.0],\n",
       " [0.9998307228088379, 0.00016923589282669127],\n",
       " [0.9998670816421509, 0.00013286595640238374],\n",
       " [0.000757101399358362, 0.999242901802063],\n",
       " [0.9999814033508301, 1.8616845409269445e-05],\n",
       " [0.9999415874481201, 5.841346501256339e-05],\n",
       " [0.9999477863311768, 5.220634557190351e-05],\n",
       " [9.248591226196368e-09, 1.0],\n",
       " [0.9999947547912598, 5.250706635706592e-06],\n",
       " [1.516290093483974e-09, 1.0],\n",
       " [0.9999902248382568, 9.828219845076092e-06],\n",
       " [0.9999910593032837, 8.93899687071098e-06],\n",
       " [1.0340244216422434e-06, 0.999998927116394],\n",
       " [0.382859468460083, 0.617140531539917],\n",
       " [0.9999969005584717, 3.088737230427796e-06],\n",
       " [0.9999842643737793, 1.567716390127316e-05],\n",
       " [0.9979426264762878, 0.002057333244010806],\n",
       " [3.332606502226554e-05, 0.9999666213989258],\n",
       " [2.1366157731961266e-09, 1.0],\n",
       " [1.9763499864433598e-11, 1.0],\n",
       " [0.9619197845458984, 0.038080278784036636],\n",
       " [0.9841183423995972, 0.015881666913628578],\n",
       " [0.999984860420227, 1.5085278391779866e-05],\n",
       " [0.9999924898147583, 7.49063565308461e-06],\n",
       " [3.84879211834388e-11, 1.0],\n",
       " [5.216919604644765e-11, 1.0],\n",
       " [4.560683386500841e-09, 1.0],\n",
       " [0.9999891519546509, 1.080996935343137e-05],\n",
       " [0.9999984502792358, 1.5008646414571558e-06],\n",
       " [0.9999345541000366, 6.543486233567819e-05],\n",
       " [0.9742010831832886, 0.025798849761486053],\n",
       " [0.9999847412109375, 1.5284625987987965e-05],\n",
       " [0.9999842643737793, 1.5683774108765647e-05],\n",
       " [0.9999786615371704, 2.1285370166879147e-05],\n",
       " [0.2513972222805023, 0.7486028075218201],\n",
       " [0.9999325275421143, 6.749897875124589e-05],\n",
       " [0.999990701675415, 9.303029401053209e-06],\n",
       " [1.5076624393373095e-08, 1.0],\n",
       " [1.8892689695348963e-05, 0.999981164932251],\n",
       " [0.9999972581863403, 2.686971583898412e-06],\n",
       " [0.9999414682388306, 5.8507681387709454e-05],\n",
       " [0.9999827146530151, 1.73380922205979e-05],\n",
       " [1.9861324744852027e-06, 0.9999979734420776],\n",
       " [0.9999914169311523, 8.524693839717656e-06],\n",
       " [0.9999881982803345, 1.179182709165616e-05],\n",
       " [0.9998366832733154, 0.0001632351049920544],\n",
       " [0.9999814033508301, 1.8598762835608795e-05],\n",
       " [1.7709123056874887e-08, 1.0],\n",
       " [0.9999819993972778, 1.7997810573433526e-05],\n",
       " [0.9999305009841919, 6.94412665325217e-05],\n",
       " [0.9997896552085876, 0.00021039381681475788],\n",
       " [1.2402335869410308e-07, 0.9999998807907104],\n",
       " [3.7068406122386932e-09, 1.0],\n",
       " [0.9999887943267822, 1.1235837519052438e-05],\n",
       " [0.9999909400939941, 9.08534275367856e-06],\n",
       " [0.9999978542327881, 2.1931730316282483e-06],\n",
       " [0.9999908208847046, 9.227218470186926e-06],\n",
       " [0.9999933242797852, 6.6293323470745236e-06],\n",
       " [0.9999958276748657, 4.172513854427962e-06],\n",
       " [8.453328592672449e-10, 1.0],\n",
       " [0.9999960660934448, 3.977119376941118e-06],\n",
       " [0.9999809265136719, 1.9105582396150567e-05],\n",
       " [0.9998533725738525, 0.00014658230065833777],\n",
       " [0.9999929666519165, 6.986426342336927e-06],\n",
       " [0.9999241828918457, 7.583263504784554e-05],\n",
       " [0.1259663999080658, 0.8740336894989014],\n",
       " [6.258264875214081e-07, 0.9999994039535522],\n",
       " [3.2222931878322925e-08, 1.0],\n",
       " [3.3832894263952085e-09, 1.0],\n",
       " [0.9999898672103882, 1.0098343409481458e-05],\n",
       " [6.202620284057048e-07, 0.9999994039535522],\n",
       " [0.9998719692230225, 0.00012805299775209278],\n",
       " [2.6420357457368482e-08, 1.0],\n",
       " [2.5465018548692653e-12, 1.0],\n",
       " [0.9999586343765259, 4.137381256441586e-05],\n",
       " [8.230202297454525e-08, 0.9999998807907104],\n",
       " [2.81497705145739e-07, 0.9999997615814209],\n",
       " [0.9999873638153076, 1.2679217434197199e-05],\n",
       " [2.0302454162290928e-11, 1.0],\n",
       " [0.9999457597732544, 5.4225358326220885e-05],\n",
       " [0.9998875856399536, 0.000112347916001454],\n",
       " [0.9999792575836182, 2.0792407667613588e-05],\n",
       " [0.9999895095825195, 1.0451965863467194e-05],\n",
       " [0.9999939203262329, 6.098209723859327e-06],\n",
       " [0.9999960660934448, 3.875157290167408e-06],\n",
       " [0.9999898672103882, 1.0076890248456039e-05],\n",
       " [1.2401313753684917e-08, 1.0],\n",
       " [0.0031606771517544985, 0.9968392848968506],\n",
       " [0.9999747276306152, 2.5291903511970304e-05],\n",
       " [0.9999244213104248, 7.55149667384103e-05],\n",
       " [0.9999749660491943, 2.5091017960221507e-05],\n",
       " [1.6834080796002127e-08, 1.0],\n",
       " [2.3548318850430405e-09, 1.0],\n",
       " [0.9999873638153076, 1.2631616300495807e-05],\n",
       " [0.9999926090240479, 7.3521605372661725e-06],\n",
       " [0.9999969005584717, 3.1050135476107243e-06],\n",
       " [0.9999651908874512, 3.4846951166400686e-05],\n",
       " [0.9999865293502808, 1.3446916454995517e-05],\n",
       " [0.9999737739562988, 2.626547939144075e-05],\n",
       " [0.9999594688415527, 4.048300252179615e-05],\n",
       " [4.228529348893062e-07, 0.9999995231628418],\n",
       " [0.9999856948852539, 1.428238374501234e-05],\n",
       " [0.9999923706054688, 7.655855370103382e-06]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t=0\n",
    "n=0\n",
    "s=len(temp)\n",
    "for i in temp:\n",
    "    t+=i[0]\n",
    "    n+=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=[t/s , n/s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original label of wav file is:1 and the predicted output is [0.3182120560104184,0.6817879402937157]\n"
     ]
    }
   ],
   "source": [
    "print('The original label of wav file is:{} and the predicted output is [{},{}]'.format( wave_file_label,output[1],output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
